{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: My conditions tracker doesn't work. I need to fix the columns by changing the delimiter. Then, I need to make sure that my 'merge' function is actually doing what I want it to.\n",
    "# Then make the plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pprint\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the files\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\alexa\\\\OneDrive\\\\Documents\\\\MSc Psychology\\\\MSc Thesis\\\\Code\\\\experiment_results_v3.csv\") # Experiment results, wrangled in R\n",
    "conditions_tracker = pd.read_csv(\"C:\\\\Users\\\\alexa\\\\OneDrive\\\\Documents\\\\MSc Psychology\\\\MSc Thesis\\\\Code\\\\experiment_conditions_tracking_semicolon.csv\", delimiter=';')\n",
    "\n",
    "# Manually check that columns match.\n",
    "# df and conditions_tracker both need: 'sentence_id', 'probe_type', 'probe_number'\n",
    "# and that conditions_tracker has 'interval_length', 'complexity', 'concept_tag'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0         ResponseId  attention  \\\n",
      "0             1  R_2E70Gw66U1MFTey          6   \n",
      "1             2  R_2E70Gw66U1MFTey          6   \n",
      "2             3  R_2E70Gw66U1MFTey          6   \n",
      "3             4  R_2E70Gw66U1MFTey          6   \n",
      "4             5  R_2E70Gw66U1MFTey          6   \n",
      "..          ...                ...        ...   \n",
      "944         945  R_8ZP9f4t8l9cLCIg          7   \n",
      "945         946  R_8ZP9f4t8l9cLCIg          7   \n",
      "946         947  R_8ZP9f4t8l9cLCIg          7   \n",
      "947         948  R_8ZP9f4t8l9cLCIg          7   \n",
      "948         949  R_8ZP9f4t8l9cLCIg          7   \n",
      "\n",
      "                        sentence_name  \\\n",
      "0               abovetruthvaluequery2   \n",
      "1                 agetruthvaluequery1   \n",
      "2          directionstruthvaluequery2   \n",
      "3               goingtruthvaluequery1   \n",
      "4            surprisetruthvaluequery1   \n",
      "..                                ...   \n",
      "944          namescontinuationprompt1   \n",
      "945  continuation3continuationprompt1   \n",
      "946            newcontinuationprompt2   \n",
      "947           copycontinuationprompt3   \n",
      "948         mattercontinuationprompt2   \n",
      "\n",
      "                                        answer  survey  row_id  score  \n",
      "0                                        False       1       1      1  \n",
      "1                                         True       1       2      1  \n",
      "2                                         True       1       3      0  \n",
      "3                                        False       1       4      1  \n",
      "4                                        False       1       5      0  \n",
      "..                                         ...     ...     ...    ...  \n",
      "944    Next, you ask whether his name is John.       6      19      1  \n",
      "945                   Next, you open the safe.       6      20      1  \n",
      "946  Next, you look at all the sparkling gold.       6      21      1  \n",
      "947                   Now, you have two lists.       6      22      1  \n",
      "948          Next, you notice the gas forming.       6      23      1  \n",
      "\n",
      "[949 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to parse the question column\n",
    "def parse_question(sentence_name):\n",
    "    match = re.match(r'([a-zA-Z0-9_]+)(truthvaluequery|continuationprompt)(\\d+)', sentence_name)\n",
    "    if match:\n",
    "        sentence_id, probe_type, probe_number = match.groups()\n",
    "        return pd.Series([sentence_id, probe_type, int(probe_number)])\n",
    "    return pd.Series([sentence_name, None, None])  # Return question for manual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the question column and create new columns\n",
    "# This is so that we can match the columns to the conditions tracker in order to add the appropriate conditions\n",
    "df[['sentence_id', 'probe_type', 'probe_number']] = df['sentence_name'].apply(parse_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0         ResponseId  attention  \\\n",
      "0             1  R_2E70Gw66U1MFTey          6   \n",
      "1             2  R_2E70Gw66U1MFTey          6   \n",
      "2             3  R_2E70Gw66U1MFTey          6   \n",
      "3             4  R_2E70Gw66U1MFTey          6   \n",
      "4             5  R_2E70Gw66U1MFTey          6   \n",
      "..          ...                ...        ...   \n",
      "944         945  R_8ZP9f4t8l9cLCIg          7   \n",
      "945         946  R_8ZP9f4t8l9cLCIg          7   \n",
      "946         947  R_8ZP9f4t8l9cLCIg          7   \n",
      "947         948  R_8ZP9f4t8l9cLCIg          7   \n",
      "948         949  R_8ZP9f4t8l9cLCIg          7   \n",
      "\n",
      "                        sentence_name  \\\n",
      "0               abovetruthvaluequery2   \n",
      "1                 agetruthvaluequery1   \n",
      "2          directionstruthvaluequery2   \n",
      "3               goingtruthvaluequery1   \n",
      "4            surprisetruthvaluequery1   \n",
      "..                                ...   \n",
      "944          namescontinuationprompt1   \n",
      "945  continuation3continuationprompt1   \n",
      "946            newcontinuationprompt2   \n",
      "947           copycontinuationprompt3   \n",
      "948         mattercontinuationprompt2   \n",
      "\n",
      "                                        answer  survey  row_id  score  \\\n",
      "0                                        False       1       1      1   \n",
      "1                                         True       1       2      1   \n",
      "2                                         True       1       3      0   \n",
      "3                                        False       1       4      1   \n",
      "4                                        False       1       5      0   \n",
      "..                                         ...     ...     ...    ...   \n",
      "944    Next, you ask whether his name is John.       6      19      1   \n",
      "945                   Next, you open the safe.       6      20      1   \n",
      "946  Next, you look at all the sparkling gold.       6      21      1   \n",
      "947                   Now, you have two lists.       6      22      1   \n",
      "948          Next, you notice the gas forming.       6      23      1   \n",
      "\n",
      "       sentence_id          probe_type  probe_number  \n",
      "0            above     truthvaluequery             2  \n",
      "1              age     truthvaluequery             1  \n",
      "2       directions     truthvaluequery             2  \n",
      "3            going     truthvaluequery             1  \n",
      "4         surprise     truthvaluequery             1  \n",
      "..             ...                 ...           ...  \n",
      "944          names  continuationprompt             1  \n",
      "945  continuation3  continuationprompt             1  \n",
      "946            new  continuationprompt             2  \n",
      "947           copy  continuationprompt             3  \n",
      "948         matter  continuationprompt             2  \n",
      "\n",
      "[949 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Inspect the data\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, ResponseId, attention, sentence_name, answer, survey, row_id, score, sentence_id, probe_type, probe_number]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where probe_type and probe_number are None (indicating no match)\n",
    "unmatched_sentences = df[df['score'].isna()]\n",
    "\n",
    "# Display the result\n",
    "print(unmatched_sentences)\n",
    "\n",
    "# Note: returns empty df, meaning parsing the question column worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename probe_type values, this matches the conditions tracker\n",
    "df['probe_type'] = df['probe_type'].replace({'truthvaluequery': 'truth_value', 'continuationprompt': 'continuation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'ResponseId', 'attention', 'sentence_name', 'answer',\n",
      "       'survey', 'row_id', 'score', 'sentence_id', 'probe_type',\n",
      "       'probe_number'],\n",
      "      dtype='object')\n",
      "Index(['survey', 'sentence_id', 'interval_length', 'probe_type', 'version',\n",
      "       'complexity', 'concept_tag'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check that the column names match\n",
    "# We need 'survey', 'probe_type', and 'sentence_id' to match\n",
    "\n",
    "print(df.columns)\n",
    "print(conditions_tracker.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert any potential mismatches in data type\n",
    "\n",
    "df['survey'] = df['survey'].astype(str)\n",
    "df['sentence_id'] = df['sentence_id'].astype(str)\n",
    "df['probe_type'] = df['probe_type'].astype(str)\n",
    "\n",
    "conditions_tracker['survey'] = conditions_tracker['survey'].astype(str)\n",
    "conditions_tracker['sentence_id'] = conditions_tracker['sentence_id'].astype(str)\n",
    "conditions_tracker['probe_type'] = conditions_tracker['probe_type'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are going to add the conditions: interval length, complexity, and concept tag\n",
    "\n",
    "merged_df = pd.merge(df, conditions_tracker, on=['survey', 'sentence_id', 'probe_type'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['above' 'age' 'directions' 'going' 'surprise' 'largest' 'shadow'\n",
      " 'surrounding' 'alive' 'ToM' 'eating' 'coming' 'taste2' 'color' 'far'\n",
      " 'more' 'completion' 'empty' 'smallest' 'continuation3' 'cutting'\n",
      " 'reciprocity' 'speed' 'age2' 'support' 'efficiency' 'fill' 'dying'\n",
      " 'touch' 'day' 'largest2' 'correspondence' 'matter' 'names' 'slower'\n",
      " 'goaldirectedness' 'dry' 'besides' 'copy' 'new' 'smallest2'\n",
      " 'continuation2']\n",
      "['eating' 'coming' 'above' 'age' 'directions' 'going' 'taste2' 'surprise'\n",
      " 'color' 'far' 'more' 'completion' 'largest' 'empty' 'shadow' 'injury_'\n",
      " 'surrounding' 'smallest' 'continuation3' 'alive' 'cutting' 'reciprocity'\n",
      " 'speed' 'ToM' 'touch' 'day' 'age2' 'support' 'largest2' 'efficiency'\n",
      " 'correspondence' 'matter' 'names' 'fill' 'dying' 'emotions_(self)' 'copy'\n",
      " 'new' 'smallest2' 'slower' 'goaldirectedness' 'dry' 'besides'\n",
      " 'continuation2' 'injury' 'emotions']\n"
     ]
    }
   ],
   "source": [
    "print(df['sentence_id'].unique())\n",
    "print(conditions_tracker['sentence_id'].unique()) # extra elements: 'injury', 'emotions', 'emotions_(self)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the conditions to the matching rows\n",
    "\n",
    "df['interval_length'] = merged_df['interval_length']\n",
    "df['complexity'] = merged_df['complexity']\n",
    "df['concept_tag'] = merged_df['concept_tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, ResponseId, attention, sentence_name, answer, survey, row_id, score, sentence_id, probe_type, probe_number, interval_length, version, complexity, concept_tag]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check if there's any missing values after merging\n",
    "\n",
    "missing_data_rows = merged_df[merged_df.isnull().any(axis=1)]\n",
    "print(missing_data_rows)\n",
    "\n",
    "# Yay it's empty!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0         ResponseId  attention  \\\n",
      "0             1  R_2E70Gw66U1MFTey          6   \n",
      "1             2  R_2E70Gw66U1MFTey          6   \n",
      "2             3  R_2E70Gw66U1MFTey          6   \n",
      "3             4  R_2E70Gw66U1MFTey          6   \n",
      "4             5  R_2E70Gw66U1MFTey          6   \n",
      "..          ...                ...        ...   \n",
      "944         945  R_8ZP9f4t8l9cLCIg          7   \n",
      "945         946  R_8ZP9f4t8l9cLCIg          7   \n",
      "946         947  R_8ZP9f4t8l9cLCIg          7   \n",
      "947         948  R_8ZP9f4t8l9cLCIg          7   \n",
      "948         949  R_8ZP9f4t8l9cLCIg          7   \n",
      "\n",
      "                        sentence_name  \\\n",
      "0               abovetruthvaluequery2   \n",
      "1                 agetruthvaluequery1   \n",
      "2          directionstruthvaluequery2   \n",
      "3               goingtruthvaluequery1   \n",
      "4            surprisetruthvaluequery1   \n",
      "..                                ...   \n",
      "944          namescontinuationprompt1   \n",
      "945  continuation3continuationprompt1   \n",
      "946            newcontinuationprompt2   \n",
      "947           copycontinuationprompt3   \n",
      "948         mattercontinuationprompt2   \n",
      "\n",
      "                                        answer survey  row_id  score  \\\n",
      "0                                        False      1       1      1   \n",
      "1                                         True      1       2      1   \n",
      "2                                         True      1       3      0   \n",
      "3                                        False      1       4      1   \n",
      "4                                        False      1       5      0   \n",
      "..                                         ...    ...     ...    ...   \n",
      "944    Next, you ask whether his name is John.      6      19      1   \n",
      "945                   Next, you open the safe.      6      20      1   \n",
      "946  Next, you look at all the sparkling gold.      6      21      1   \n",
      "947                   Now, you have two lists.      6      22      1   \n",
      "948          Next, you notice the gas forming.      6      23      1   \n",
      "\n",
      "       sentence_id    probe_type  probe_number  interval_length   version  \\\n",
      "0            above   truth_value             2                4  original   \n",
      "1              age   truth_value             1                4  original   \n",
      "2       directions   truth_value             2                2  original   \n",
      "3            going   truth_value             1                5  original   \n",
      "4         surprise   truth_value             1                4  original   \n",
      "..             ...           ...           ...              ...       ...   \n",
      "944          names  continuation             1                1  shuffled   \n",
      "945  continuation3  continuation             1                2  shuffled   \n",
      "946            new  continuation             2                0  shuffled   \n",
      "947           copy  continuation             3                4  shuffled   \n",
      "948         matter  continuation             2                3  shuffled   \n",
      "\n",
      "     complexity concept_tag  \n",
      "0           1.0    geometry  \n",
      "1           1.0    temporal  \n",
      "2           1.0    geometry  \n",
      "3           1.0      social  \n",
      "4           1.0      social  \n",
      "..          ...         ...  \n",
      "944         3.0      social  \n",
      "945         3.0    temporal  \n",
      "946         2.0    temporal  \n",
      "947         2.0      social  \n",
      "948         3.0    geometry  \n",
      "\n",
      "[949 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split truth value and continuation prompts out \n",
    "\n",
    "truth_value_df = merged_df[merged_df['probe_type'] == 'truth_value']\n",
    "continuation_df = merged_df[merged_df['probe_type'] == 'continuation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'ResponseId', 'attention', 'sentence_name', 'answer',\n",
      "       'survey', 'row_id', 'score', 'sentence_id', 'probe_type',\n",
      "       'probe_number', 'interval_length', 'version', 'complexity',\n",
      "       'concept_tag'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(truth_value_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save locally\n",
    "\n",
    "truth_value_df.to_csv('human_truth_value_results_14_11.csv', index=False)\n",
    "continuation_df.to_csv('human_continuation_results_14_11.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
